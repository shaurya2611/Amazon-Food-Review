{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obejctive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Given a review, determine whether the review is positive (rating of 4 or 5) or negative (rating of 1 or 2).\n",
    "* A rating of 4 or 5 can be cosnidered as a positive review. A rating of 1 or 2 can be considered as negative one. A review of rating 3 is considered nuetral and such reviews are ignored from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection = sqlite3.connect(\"D:\\\\Data Science\\\\Projects\\\\Amazon food review\\\\database.sqlite\")\n",
    "df = pd.read_sql_query(\"Select * from  Reviews\", connection)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(525814, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since score of 3 is considered neutral hence removing it from the database table--\n",
    "\n",
    "df = pd.read_sql_query(\"Select * From Reviews where Score!=3\",connection)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score (4,5) are considered + ive (1)\n",
    "# Score (1,2) are considered - ive (0)\n",
    "\n",
    "def score_manage(x):\n",
    "    if x in [4,5]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      1  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      1  1219017600   \n",
       "3                     3                       3      0  1307923200   \n",
       "4                     0                       0      1  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Score = df.Score.map(score_manage)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138706</th>\n",
       "      <td>150524</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138688</th>\n",
       "      <td>150506</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A2IW4PEEKO2R0U</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1194739200</td>\n",
       "      <td>Love the book, miss the hard cover version</td>\n",
       "      <td>I grew up reading these Sendak books, and watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138689</th>\n",
       "      <td>150507</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A1S4A3IQ2MU7V4</td>\n",
       "      <td>sally sue \"sally sue\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>chicken soup with rice months</td>\n",
       "      <td>This is a fun way for children to learn their ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138690</th>\n",
       "      <td>150508</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>AZGXZ2UUK6X</td>\n",
       "      <td>Catherine Hallberg \"(Kate)\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1076025600</td>\n",
       "      <td>a good swingy rhythm for reading aloud</td>\n",
       "      <td>This is a great little book to read aloud- it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138691</th>\n",
       "      <td>150509</td>\n",
       "      <td>0006641040</td>\n",
       "      <td>A3CMRKGE0P909G</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1018396800</td>\n",
       "      <td>A great way to learn the months</td>\n",
       "      <td>This is a book of poetry about the months of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                  ProfileName  \\\n",
       "138706  150524  0006641040   ACITT7DI6IDDL              shari zychinski   \n",
       "138688  150506  0006641040  A2IW4PEEKO2R0U                        Tracy   \n",
       "138689  150507  0006641040  A1S4A3IQ2MU7V4        sally sue \"sally sue\"   \n",
       "138690  150508  0006641040     AZGXZ2UUK6X  Catherine Hallberg \"(Kate)\"   \n",
       "138691  150509  0006641040  A3CMRKGE0P909G                       Teresa   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "138706                     0                       0      1   939340800   \n",
       "138688                     1                       1      1  1194739200   \n",
       "138689                     1                       1      1  1191456000   \n",
       "138690                     1                       1      1  1076025600   \n",
       "138691                     3                       4      1  1018396800   \n",
       "\n",
       "                                           Summary  \\\n",
       "138706                   EVERY book is educational   \n",
       "138688  Love the book, miss the hard cover version   \n",
       "138689               chicken soup with rice months   \n",
       "138690      a good swingy rhythm for reading aloud   \n",
       "138691             A great way to learn the months   \n",
       "\n",
       "                                                     Text  \n",
       "138706  this witty little book makes my son laugh at l...  \n",
       "138688  I grew up reading these Sendak books, and watc...  \n",
       "138689  This is a fun way for children to learn their ...  \n",
       "138690  This is a great little book to read aloud- it ...  \n",
       "138691  This is a book of poetry about the months of t...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for more visualtization sorting data according to the ProductID\n",
    "\n",
    "sorted_df = df.sort_values(axis=0,by=['ProductId'] , na_position='last', kind='quicksort' )\n",
    "sorted_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157843</th>\n",
       "      <td>171154</td>\n",
       "      <td>7310172001</td>\n",
       "      <td>AJD41FBJD9010</td>\n",
       "      <td>N. Ferguson \"Two, Daisy, Hannah, and Kitten\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1233360000</td>\n",
       "      <td>best dog treat-- great for training---  all do...</td>\n",
       "      <td>Freeze dried liver has a hypnotic effect on do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157908</th>\n",
       "      <td>171223</td>\n",
       "      <td>7310172001</td>\n",
       "      <td>AJD41FBJD9010</td>\n",
       "      <td>N. Ferguson \"Two, Daisy, Hannah, and Kitten\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1233360000</td>\n",
       "      <td>best dog treat-- great for training---  all do...</td>\n",
       "      <td>Freeze dried liver has a hypnotic effect on do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157876</th>\n",
       "      <td>171189</td>\n",
       "      <td>7310172001</td>\n",
       "      <td>AJD41FBJD9010</td>\n",
       "      <td>N. Ferguson \"Two, Daisy, Hannah, and Kitten\"</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1233360000</td>\n",
       "      <td>NO waste at all ----  great for training  ----...</td>\n",
       "      <td>Freeze dried liver has a hypnotic effect on do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200631</th>\n",
       "      <td>217420</td>\n",
       "      <td>7310172101</td>\n",
       "      <td>AJD41FBJD9010</td>\n",
       "      <td>N. Ferguson \"Two, Daisy, Hannah, and Kitten\"</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1233360000</td>\n",
       "      <td>NO waste at all ----  great for training  ----...</td>\n",
       "      <td>Freeze dried liver has a hypnotic effect on do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200596</th>\n",
       "      <td>217383</td>\n",
       "      <td>7310172101</td>\n",
       "      <td>AJD41FBJD9010</td>\n",
       "      <td>N. Ferguson \"Two, Daisy, Hannah, and Kitten\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1233360000</td>\n",
       "      <td>dogs LOVE it--  best treat for rewards and tra...</td>\n",
       "      <td>Freeze dried liver has a hypnotic effect on do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200597</th>\n",
       "      <td>217384</td>\n",
       "      <td>7310172101</td>\n",
       "      <td>AJD41FBJD9010</td>\n",
       "      <td>N. Ferguson \"Two, Daisy, Hannah, and Kitten\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1233360000</td>\n",
       "      <td>best dog treat-- great for training---  all do...</td>\n",
       "      <td>Freeze dried liver has a hypnotic effect on do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341818</th>\n",
       "      <td>369802</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A36JDIN9RAAIEC</td>\n",
       "      <td>Jon</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1292976000</td>\n",
       "      <td>Don't fall prey to fads and anecdotal reviews</td>\n",
       "      <td>I have two cats, one 6 and one 2 years old. Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341820</th>\n",
       "      <td>369804</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341815</th>\n",
       "      <td>369799</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A25C5MVVCIYT5D</td>\n",
       "      <td>Natalie Dawn</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1304726400</td>\n",
       "      <td>Nothing else works</td>\n",
       "      <td>I understand all the complaints about Science ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341798</th>\n",
       "      <td>369781</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341802</th>\n",
       "      <td>369786</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341806</th>\n",
       "      <td>369790</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A36JDIN9RAAIEC</td>\n",
       "      <td>Jon</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1292976000</td>\n",
       "      <td>Great product, but trust your vet not the hype</td>\n",
       "      <td>I have two cats, one 6 and one 2 years old. Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341807</th>\n",
       "      <td>369791</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341810</th>\n",
       "      <td>369794</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341811</th>\n",
       "      <td>369795</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341812</th>\n",
       "      <td>369796</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341858</th>\n",
       "      <td>369845</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341870</th>\n",
       "      <td>369857</td>\n",
       "      <td>B000084DWM</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379416</th>\n",
       "      <td>410243</td>\n",
       "      <td>B000084EZ4</td>\n",
       "      <td>A29JUMRL1US6YP</td>\n",
       "      <td>HTBK</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Fantastic Food for Good Cat Health</td>\n",
       "      <td>The pet food industry can be one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379440</th>\n",
       "      <td>410268</td>\n",
       "      <td>B000084EZ4</td>\n",
       "      <td>A29JUMRL1US6YP</td>\n",
       "      <td>HTBK</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Fantastic Food for Good Cat Health</td>\n",
       "      <td>The pet food industry can be one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379439</th>\n",
       "      <td>410267</td>\n",
       "      <td>B000084EZ4</td>\n",
       "      <td>A29JUMRL1US6YP</td>\n",
       "      <td>HTBK</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Fantastic Food for Good Cat Health</td>\n",
       "      <td>The pet food industry can be one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379466</th>\n",
       "      <td>410296</td>\n",
       "      <td>B000084EZ4</td>\n",
       "      <td>A34UV2FFXJPS3T</td>\n",
       "      <td>Susan Ackoff</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>Great Cat Food</td>\n",
       "      <td>Wellness wet cat food is terrific.&lt;br /&gt;My thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379437</th>\n",
       "      <td>410265</td>\n",
       "      <td>B000084EZ4</td>\n",
       "      <td>A2FGXWWR8ZU59C</td>\n",
       "      <td>Thomas Lawrence</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1292198400</td>\n",
       "      <td>Cats love the food, but no pull-tab top, and d...</td>\n",
       "      <td>I appreciate being able to buy this larger, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379427</th>\n",
       "      <td>410254</td>\n",
       "      <td>B000084EZ4</td>\n",
       "      <td>A29JUMRL1US6YP</td>\n",
       "      <td>HTBK</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Fantastic Food for Good Cat Health</td>\n",
       "      <td>The pet food industry can be one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379474</th>\n",
       "      <td>410304</td>\n",
       "      <td>B000084EZ4</td>\n",
       "      <td>A29JUMRL1US6YP</td>\n",
       "      <td>HTBK</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Fantastic Food for Good Cat Health</td>\n",
       "      <td>The pet food industry can be one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449617</th>\n",
       "      <td>486153</td>\n",
       "      <td>B00008CQVA</td>\n",
       "      <td>A29JUMRL1US6YP</td>\n",
       "      <td>HTBK</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Fantastic Food for Good Cat Health</td>\n",
       "      <td>The pet food industry can be one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449566</th>\n",
       "      <td>486099</td>\n",
       "      <td>B00008CQVA</td>\n",
       "      <td>A29JUMRL1US6YP</td>\n",
       "      <td>HTBK</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Fantastic Food for Good Cat Health</td>\n",
       "      <td>The pet food industry can be one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449514</th>\n",
       "      <td>486040</td>\n",
       "      <td>B00008CQVA</td>\n",
       "      <td>A29JUMRL1US6YP</td>\n",
       "      <td>HTBK</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Fantastic Food for Good Cat Health</td>\n",
       "      <td>The pet food industry can be one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449570</th>\n",
       "      <td>486103</td>\n",
       "      <td>B00008CQVA</td>\n",
       "      <td>A29JUMRL1US6YP</td>\n",
       "      <td>HTBK</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1278201600</td>\n",
       "      <td>Fantastic Food for Good Cat Health</td>\n",
       "      <td>The pet food industry can be one of the most i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449527</th>\n",
       "      <td>486055</td>\n",
       "      <td>B00008CQVA</td>\n",
       "      <td>A34UV2FFXJPS3T</td>\n",
       "      <td>Susan Ackoff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1294185600</td>\n",
       "      <td>My Cats love it</td>\n",
       "      <td>Wellness wet cat food is terrific.&lt;br /&gt;My thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296656</th>\n",
       "      <td>321348</td>\n",
       "      <td>B008RWUHA6</td>\n",
       "      <td>A2BQWD54CXBX6R</td>\n",
       "      <td>Kym McNabney \"Writing From The Soul\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1320364800</td>\n",
       "      <td>SURPRISINGLY WOUNDERFUL</td>\n",
       "      <td>Anything that has the following words grabs my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168384</th>\n",
       "      <td>182580</td>\n",
       "      <td>B008RWUKXK</td>\n",
       "      <td>A2BQWD54CXBX6R</td>\n",
       "      <td>Kym McNabney \"Writing From The Soul\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1320364800</td>\n",
       "      <td>SURPRISINGLY WOUNDERFUL</td>\n",
       "      <td>Anything that has the following words grabs my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349040</th>\n",
       "      <td>377543</td>\n",
       "      <td>B00975HC9G</td>\n",
       "      <td>A20P8VC55KPPCT</td>\n",
       "      <td>FL Mom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1310860800</td>\n",
       "      <td>Love all HappyBaby Tots!</td>\n",
       "      <td>My kids (18 mo and 3 yrs) love the HappyBaby T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462244</th>\n",
       "      <td>499847</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462262</th>\n",
       "      <td>499865</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462257</th>\n",
       "      <td>499860</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A25C5MVVCIYT5D</td>\n",
       "      <td>Natalie Dawn</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1304726400</td>\n",
       "      <td>Nothing else works</td>\n",
       "      <td>I understand all the complaints about Science ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462254</th>\n",
       "      <td>499857</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462253</th>\n",
       "      <td>499856</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462252</th>\n",
       "      <td>499855</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462248</th>\n",
       "      <td>499851</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A36JDIN9RAAIEC</td>\n",
       "      <td>Jon</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1292976000</td>\n",
       "      <td>Great product, but trust your vet not the hype</td>\n",
       "      <td>I have two cats, one 6 and one 2 years old. Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462249</th>\n",
       "      <td>499852</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462259</th>\n",
       "      <td>499862</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A36JDIN9RAAIEC</td>\n",
       "      <td>Jon</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1292976000</td>\n",
       "      <td>Great product, but trust your vet not the hype</td>\n",
       "      <td>I have two cats, one 6 and one 2 years old. Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462311</th>\n",
       "      <td>499917</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462312</th>\n",
       "      <td>499918</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462300</th>\n",
       "      <td>499906</td>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411619</th>\n",
       "      <td>445168</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A36JDIN9RAAIEC</td>\n",
       "      <td>Jon</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1292976000</td>\n",
       "      <td>Don't fall prey to fads and anecdotal reviews</td>\n",
       "      <td>I have two cats, one 6 and one 2 years old. Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411613</th>\n",
       "      <td>445162</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411659</th>\n",
       "      <td>445211</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411599</th>\n",
       "      <td>445147</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411671</th>\n",
       "      <td>445223</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411670</th>\n",
       "      <td>445222</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411612</th>\n",
       "      <td>445161</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411608</th>\n",
       "      <td>445157</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411607</th>\n",
       "      <td>445156</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A36JDIN9RAAIEC</td>\n",
       "      <td>Jon</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1292976000</td>\n",
       "      <td>Great product, but trust your vet not the hype</td>\n",
       "      <td>I have two cats, one 6 and one 2 years old. Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411611</th>\n",
       "      <td>445160</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411603</th>\n",
       "      <td>445152</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411633</th>\n",
       "      <td>445184</td>\n",
       "      <td>B009GHI5Q4</td>\n",
       "      <td>A25C5MVVCIYT5D</td>\n",
       "      <td>Natalie Dawn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1304726400</td>\n",
       "      <td>The only thing that worked</td>\n",
       "      <td>I understand all the complaints about Science ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62138</th>\n",
       "      <td>67510</td>\n",
       "      <td>B009GHI6I6</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62140</th>\n",
       "      <td>67512</td>\n",
       "      <td>B009GHI6I6</td>\n",
       "      <td>A2ISKAWUPGGOLZ</td>\n",
       "      <td>M. S. Handley</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1310774400</td>\n",
       "      <td>Kitty Junk Food</td>\n",
       "      <td>We have five cats - one an elderly cat of 15 y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386483</th>\n",
       "      <td>417942</td>\n",
       "      <td>B009RB4GO4</td>\n",
       "      <td>A21GDMT9JN2A5Y</td>\n",
       "      <td>Wayward Traveller \"WaywardT\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1309910400</td>\n",
       "      <td>Does not taste at all like I thought I would :)</td>\n",
       "      <td>I really had high expectations of this product...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1227 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId  \\\n",
       "157843  171154  7310172001   AJD41FBJD9010   \n",
       "157908  171223  7310172001   AJD41FBJD9010   \n",
       "157876  171189  7310172001   AJD41FBJD9010   \n",
       "200631  217420  7310172101   AJD41FBJD9010   \n",
       "200596  217383  7310172101   AJD41FBJD9010   \n",
       "200597  217384  7310172101   AJD41FBJD9010   \n",
       "341818  369802  B000084DWM  A36JDIN9RAAIEC   \n",
       "341820  369804  B000084DWM  A3TVZM3ZIXG8YW   \n",
       "341815  369799  B000084DWM  A25C5MVVCIYT5D   \n",
       "341798  369781  B000084DWM  A3TVZM3ZIXG8YW   \n",
       "341802  369786  B000084DWM  A3TVZM3ZIXG8YW   \n",
       "341806  369790  B000084DWM  A36JDIN9RAAIEC   \n",
       "341807  369791  B000084DWM  A3TVZM3ZIXG8YW   \n",
       "341810  369794  B000084DWM  A3TVZM3ZIXG8YW   \n",
       "341811  369795  B000084DWM  A3TVZM3ZIXG8YW   \n",
       "341812  369796  B000084DWM  A3TVZM3ZIXG8YW   \n",
       "341858  369845  B000084DWM  A3TVZM3ZIXG8YW   \n",
       "341870  369857  B000084DWM  A3TVZM3ZIXG8YW   \n",
       "379416  410243  B000084EZ4  A29JUMRL1US6YP   \n",
       "379440  410268  B000084EZ4  A29JUMRL1US6YP   \n",
       "379439  410267  B000084EZ4  A29JUMRL1US6YP   \n",
       "379466  410296  B000084EZ4  A34UV2FFXJPS3T   \n",
       "379437  410265  B000084EZ4  A2FGXWWR8ZU59C   \n",
       "379427  410254  B000084EZ4  A29JUMRL1US6YP   \n",
       "379474  410304  B000084EZ4  A29JUMRL1US6YP   \n",
       "449617  486153  B00008CQVA  A29JUMRL1US6YP   \n",
       "449566  486099  B00008CQVA  A29JUMRL1US6YP   \n",
       "449514  486040  B00008CQVA  A29JUMRL1US6YP   \n",
       "449570  486103  B00008CQVA  A29JUMRL1US6YP   \n",
       "449527  486055  B00008CQVA  A34UV2FFXJPS3T   \n",
       "...        ...         ...             ...   \n",
       "296656  321348  B008RWUHA6  A2BQWD54CXBX6R   \n",
       "168384  182580  B008RWUKXK  A2BQWD54CXBX6R   \n",
       "349040  377543  B00975HC9G  A20P8VC55KPPCT   \n",
       "462244  499847  B009B87SAC  A3TVZM3ZIXG8YW   \n",
       "462262  499865  B009B87SAC  A3TVZM3ZIXG8YW   \n",
       "462257  499860  B009B87SAC  A25C5MVVCIYT5D   \n",
       "462254  499857  B009B87SAC  A3TVZM3ZIXG8YW   \n",
       "462253  499856  B009B87SAC  A3TVZM3ZIXG8YW   \n",
       "462252  499855  B009B87SAC  A3TVZM3ZIXG8YW   \n",
       "462248  499851  B009B87SAC  A36JDIN9RAAIEC   \n",
       "462249  499852  B009B87SAC  A3TVZM3ZIXG8YW   \n",
       "462259  499862  B009B87SAC  A36JDIN9RAAIEC   \n",
       "462311  499917  B009B87SAC  A3TVZM3ZIXG8YW   \n",
       "462312  499918  B009B87SAC  A3TVZM3ZIXG8YW   \n",
       "462300  499906  B009B87SAC  A3TVZM3ZIXG8YW   \n",
       "411619  445168  B009GHI5Q4  A36JDIN9RAAIEC   \n",
       "411613  445162  B009GHI5Q4  A3TVZM3ZIXG8YW   \n",
       "411659  445211  B009GHI5Q4  A3TVZM3ZIXG8YW   \n",
       "411599  445147  B009GHI5Q4  A3TVZM3ZIXG8YW   \n",
       "411671  445223  B009GHI5Q4  A3TVZM3ZIXG8YW   \n",
       "411670  445222  B009GHI5Q4  A3TVZM3ZIXG8YW   \n",
       "411612  445161  B009GHI5Q4  A3TVZM3ZIXG8YW   \n",
       "411608  445157  B009GHI5Q4  A3TVZM3ZIXG8YW   \n",
       "411607  445156  B009GHI5Q4  A36JDIN9RAAIEC   \n",
       "411611  445160  B009GHI5Q4  A3TVZM3ZIXG8YW   \n",
       "411603  445152  B009GHI5Q4  A3TVZM3ZIXG8YW   \n",
       "411633  445184  B009GHI5Q4  A25C5MVVCIYT5D   \n",
       "62138    67510  B009GHI6I6  A3TVZM3ZIXG8YW   \n",
       "62140    67512  B009GHI6I6  A2ISKAWUPGGOLZ   \n",
       "386483  417942  B009RB4GO4  A21GDMT9JN2A5Y   \n",
       "\n",
       "                                         ProfileName  HelpfulnessNumerator  \\\n",
       "157843  N. Ferguson \"Two, Daisy, Hannah, and Kitten\"                     0   \n",
       "157908  N. Ferguson \"Two, Daisy, Hannah, and Kitten\"                     1   \n",
       "157876  N. Ferguson \"Two, Daisy, Hannah, and Kitten\"                    39   \n",
       "200631  N. Ferguson \"Two, Daisy, Hannah, and Kitten\"                    39   \n",
       "200596  N. Ferguson \"Two, Daisy, Hannah, and Kitten\"                     0   \n",
       "200597  N. Ferguson \"Two, Daisy, Hannah, and Kitten\"                     0   \n",
       "341818                                           Jon                     2   \n",
       "341820                             christopher hayes                    33   \n",
       "341815                                  Natalie Dawn                     2   \n",
       "341798                             christopher hayes                    19   \n",
       "341802                             christopher hayes                    18   \n",
       "341806                                           Jon                     3   \n",
       "341807                             christopher hayes                     3   \n",
       "341810                             christopher hayes                     7   \n",
       "341811                             christopher hayes                    11   \n",
       "341812                             christopher hayes                    11   \n",
       "341858                             christopher hayes                     2   \n",
       "341870                             christopher hayes                     6   \n",
       "379416                                          HTBK                    12   \n",
       "379440                                          HTBK                     3   \n",
       "379439                                          HTBK                     3   \n",
       "379466                                  Susan Ackoff                     2   \n",
       "379437                               Thomas Lawrence                     3   \n",
       "379427                                          HTBK                     4   \n",
       "379474                                          HTBK                     4   \n",
       "449617                                          HTBK                     4   \n",
       "449566                                          HTBK                     7   \n",
       "449514                                          HTBK                     3   \n",
       "449570                                          HTBK                     4   \n",
       "449527                                  Susan Ackoff                     0   \n",
       "...                                              ...                   ...   \n",
       "296656          Kym McNabney \"Writing From The Soul\"                     1   \n",
       "168384          Kym McNabney \"Writing From The Soul\"                     1   \n",
       "349040                                        FL Mom                     0   \n",
       "462244                             christopher hayes                    18   \n",
       "462262                             christopher hayes                    33   \n",
       "462257                                  Natalie Dawn                     2   \n",
       "462254                             christopher hayes                    11   \n",
       "462253                             christopher hayes                    11   \n",
       "462252                             christopher hayes                     7   \n",
       "462248                                           Jon                     3   \n",
       "462249                             christopher hayes                     3   \n",
       "462259                                           Jon                     2   \n",
       "462311                             christopher hayes                     6   \n",
       "462312                             christopher hayes                     6   \n",
       "462300                             christopher hayes                     2   \n",
       "411619                                           Jon                     2   \n",
       "411613                             christopher hayes                    11   \n",
       "411659                             christopher hayes                     2   \n",
       "411599                             christopher hayes                    19   \n",
       "411671                             christopher hayes                     6   \n",
       "411670                             christopher hayes                     6   \n",
       "411612                             christopher hayes                    11   \n",
       "411608                             christopher hayes                     3   \n",
       "411607                                           Jon                     3   \n",
       "411611                             christopher hayes                     7   \n",
       "411603                             christopher hayes                    18   \n",
       "411633                                  Natalie Dawn                     1   \n",
       "62138                              christopher hayes                     7   \n",
       "62140                                  M. S. Handley                     2   \n",
       "386483                  Wayward Traveller \"WaywardT\"                     0   \n",
       "\n",
       "        HelpfulnessDenominator  Score        Time  \\\n",
       "157843                       0      1  1233360000   \n",
       "157908                       1      1  1233360000   \n",
       "157876                      51      1  1233360000   \n",
       "200631                      51      1  1233360000   \n",
       "200596                       0      1  1233360000   \n",
       "200597                       0      1  1233360000   \n",
       "341818                       2      1  1292976000   \n",
       "341820                      48      0  1291420800   \n",
       "341815                       2      1  1304726400   \n",
       "341798                      21      0  1291420800   \n",
       "341802                      24      0  1291420800   \n",
       "341806                       3      1  1292976000   \n",
       "341807                       3      0  1291420800   \n",
       "341810                       9      0  1291420800   \n",
       "341811                      15      0  1291420800   \n",
       "341812                      15      0  1291420800   \n",
       "341858                       4      0  1291420800   \n",
       "341870                      15      0  1291420800   \n",
       "379416                      14      1  1278201600   \n",
       "379440                       3      1  1278201600   \n",
       "379439                       3      1  1278201600   \n",
       "379466                       2      1  1294185600   \n",
       "379437                       3      1  1292198400   \n",
       "379427                       4      1  1278201600   \n",
       "379474                       5      1  1278201600   \n",
       "449617                       5      1  1278201600   \n",
       "449566                       8      1  1278201600   \n",
       "449514                       4      1  1278201600   \n",
       "449570                       4      1  1278201600   \n",
       "449527                       0      1  1294185600   \n",
       "...                        ...    ...         ...   \n",
       "296656                       1      1  1320364800   \n",
       "168384                       1      1  1320364800   \n",
       "349040                       0      1  1310860800   \n",
       "462244                      24      0  1291420800   \n",
       "462262                      48      0  1291420800   \n",
       "462257                       2      1  1304726400   \n",
       "462254                      15      0  1291420800   \n",
       "462253                      15      0  1291420800   \n",
       "462252                       9      0  1291420800   \n",
       "462248                       3      1  1292976000   \n",
       "462249                       3      0  1291420800   \n",
       "462259                       2      1  1292976000   \n",
       "462311                      14      0  1291420800   \n",
       "462312                      15      0  1291420800   \n",
       "462300                       4      0  1291420800   \n",
       "411619                       2      1  1292976000   \n",
       "411613                      15      0  1291420800   \n",
       "411659                       4      0  1291420800   \n",
       "411599                      21      0  1291420800   \n",
       "411671                      15      0  1291420800   \n",
       "411670                      14      0  1291420800   \n",
       "411612                      15      0  1291420800   \n",
       "411608                       3      0  1291420800   \n",
       "411607                       3      1  1292976000   \n",
       "411611                       9      0  1291420800   \n",
       "411603                      24      0  1291420800   \n",
       "411633                       1      1  1304726400   \n",
       "62138                       11      0  1291420800   \n",
       "62140                        4      0  1310774400   \n",
       "386483                       1      0  1309910400   \n",
       "\n",
       "                                                  Summary  \\\n",
       "157843  best dog treat-- great for training---  all do...   \n",
       "157908  best dog treat-- great for training---  all do...   \n",
       "157876  NO waste at all ----  great for training  ----...   \n",
       "200631  NO waste at all ----  great for training  ----...   \n",
       "200596  dogs LOVE it--  best treat for rewards and tra...   \n",
       "200597  best dog treat-- great for training---  all do...   \n",
       "341818      Don't fall prey to fads and anecdotal reviews   \n",
       "341820  Filler food is empty, leaves your cat always n...   \n",
       "341815                                 Nothing else works   \n",
       "341798  Filler food is empty, leaves your cat always n...   \n",
       "341802  Filler food is empty, leaves your cat always n...   \n",
       "341806     Great product, but trust your vet not the hype   \n",
       "341807  Filler food is empty, leaves your cat always n...   \n",
       "341810  Filler food is empty, leaves your cat always n...   \n",
       "341811  Filler food is empty, leaves your cat always n...   \n",
       "341812  Filler food is empty, leaves your cat always n...   \n",
       "341858  Filler food is empty, leaves your cat always n...   \n",
       "341870  Filler food is empty, leaves your cat always n...   \n",
       "379416                 Fantastic Food for Good Cat Health   \n",
       "379440                 Fantastic Food for Good Cat Health   \n",
       "379439                 Fantastic Food for Good Cat Health   \n",
       "379466                                     Great Cat Food   \n",
       "379437  Cats love the food, but no pull-tab top, and d...   \n",
       "379427                 Fantastic Food for Good Cat Health   \n",
       "379474                 Fantastic Food for Good Cat Health   \n",
       "449617                 Fantastic Food for Good Cat Health   \n",
       "449566                 Fantastic Food for Good Cat Health   \n",
       "449514                 Fantastic Food for Good Cat Health   \n",
       "449570                 Fantastic Food for Good Cat Health   \n",
       "449527                                    My Cats love it   \n",
       "...                                                   ...   \n",
       "296656                            SURPRISINGLY WOUNDERFUL   \n",
       "168384                            SURPRISINGLY WOUNDERFUL   \n",
       "349040                           Love all HappyBaby Tots!   \n",
       "462244  Filler food is empty, leaves your cat always n...   \n",
       "462262  Filler food is empty, leaves your cat always n...   \n",
       "462257                                 Nothing else works   \n",
       "462254  Filler food is empty, leaves your cat always n...   \n",
       "462253  Filler food is empty, leaves your cat always n...   \n",
       "462252  Filler food is empty, leaves your cat always n...   \n",
       "462248     Great product, but trust your vet not the hype   \n",
       "462249  Filler food is empty, leaves your cat always n...   \n",
       "462259     Great product, but trust your vet not the hype   \n",
       "462311  Filler food is empty, leaves your cat always n...   \n",
       "462312  Filler food is empty, leaves your cat always n...   \n",
       "462300  Filler food is empty, leaves your cat always n...   \n",
       "411619      Don't fall prey to fads and anecdotal reviews   \n",
       "411613  Filler food is empty, leaves your cat always n...   \n",
       "411659  Filler food is empty, leaves your cat always n...   \n",
       "411599  Filler food is empty, leaves your cat always n...   \n",
       "411671  Filler food is empty, leaves your cat always n...   \n",
       "411670  Filler food is empty, leaves your cat always n...   \n",
       "411612  Filler food is empty, leaves your cat always n...   \n",
       "411608  Filler food is empty, leaves your cat always n...   \n",
       "411607     Great product, but trust your vet not the hype   \n",
       "411611  Filler food is empty, leaves your cat always n...   \n",
       "411603  Filler food is empty, leaves your cat always n...   \n",
       "411633                         The only thing that worked   \n",
       "62138   Filler food is empty, leaves your cat always n...   \n",
       "62140                                     Kitty Junk Food   \n",
       "386483    Does not taste at all like I thought I would :)   \n",
       "\n",
       "                                                     Text  \n",
       "157843  Freeze dried liver has a hypnotic effect on do...  \n",
       "157908  Freeze dried liver has a hypnotic effect on do...  \n",
       "157876  Freeze dried liver has a hypnotic effect on do...  \n",
       "200631  Freeze dried liver has a hypnotic effect on do...  \n",
       "200596  Freeze dried liver has a hypnotic effect on do...  \n",
       "200597  Freeze dried liver has a hypnotic effect on do...  \n",
       "341818  I have two cats, one 6 and one 2 years old. Bo...  \n",
       "341820  This review will make me sound really stupid, ...  \n",
       "341815  I understand all the complaints about Science ...  \n",
       "341798  This review will make me sound really stupid, ...  \n",
       "341802  This review will make me sound really stupid, ...  \n",
       "341806  I have two cats, one 6 and one 2 years old. Bo...  \n",
       "341807  This review will make me sound really stupid, ...  \n",
       "341810  This review will make me sound really stupid, ...  \n",
       "341811  This review will make me sound really stupid, ...  \n",
       "341812  This review will make me sound really stupid, ...  \n",
       "341858  This review will make me sound really stupid, ...  \n",
       "341870  This review will make me sound really stupid, ...  \n",
       "379416  The pet food industry can be one of the most i...  \n",
       "379440  The pet food industry can be one of the most i...  \n",
       "379439  The pet food industry can be one of the most i...  \n",
       "379466  Wellness wet cat food is terrific.<br />My thr...  \n",
       "379437  I appreciate being able to buy this larger, mo...  \n",
       "379427  The pet food industry can be one of the most i...  \n",
       "379474  The pet food industry can be one of the most i...  \n",
       "449617  The pet food industry can be one of the most i...  \n",
       "449566  The pet food industry can be one of the most i...  \n",
       "449514  The pet food industry can be one of the most i...  \n",
       "449570  The pet food industry can be one of the most i...  \n",
       "449527  Wellness wet cat food is terrific.<br />My thr...  \n",
       "...                                                   ...  \n",
       "296656  Anything that has the following words grabs my...  \n",
       "168384  Anything that has the following words grabs my...  \n",
       "349040  My kids (18 mo and 3 yrs) love the HappyBaby T...  \n",
       "462244  This review will make me sound really stupid, ...  \n",
       "462262  This review will make me sound really stupid, ...  \n",
       "462257  I understand all the complaints about Science ...  \n",
       "462254  This review will make me sound really stupid, ...  \n",
       "462253  This review will make me sound really stupid, ...  \n",
       "462252  This review will make me sound really stupid, ...  \n",
       "462248  I have two cats, one 6 and one 2 years old. Bo...  \n",
       "462249  This review will make me sound really stupid, ...  \n",
       "462259  I have two cats, one 6 and one 2 years old. Bo...  \n",
       "462311  This review will make me sound really stupid, ...  \n",
       "462312  This review will make me sound really stupid, ...  \n",
       "462300  This review will make me sound really stupid, ...  \n",
       "411619  I have two cats, one 6 and one 2 years old. Bo...  \n",
       "411613  This review will make me sound really stupid, ...  \n",
       "411659  This review will make me sound really stupid, ...  \n",
       "411599  This review will make me sound really stupid, ...  \n",
       "411671  This review will make me sound really stupid, ...  \n",
       "411670  This review will make me sound really stupid, ...  \n",
       "411612  This review will make me sound really stupid, ...  \n",
       "411608  This review will make me sound really stupid, ...  \n",
       "411607  I have two cats, one 6 and one 2 years old. Bo...  \n",
       "411611  This review will make me sound really stupid, ...  \n",
       "411603  This review will make me sound really stupid, ...  \n",
       "411633  I understand all the complaints about Science ...  \n",
       "62138   This review will make me sound really stupid, ...  \n",
       "62140   We have five cats - one an elderly cat of 15 y...  \n",
       "386483  I really had high expectations of this product...  \n",
       "\n",
       "[1227 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this df shows the DUplicate records are present in the table\n",
    "\n",
    "sorted_df[sorted_df.duplicated(subset=['ProductId','UserId','Text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524587, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['ProductId','UserId','Text'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 524587 entries, 0 to 525813\n",
      "Data columns (total 10 columns):\n",
      "Id                        524587 non-null int64\n",
      "ProductId                 524587 non-null object\n",
      "UserId                    524587 non-null object\n",
      "ProfileName               524587 non-null object\n",
      "HelpfulnessNumerator      524587 non-null int64\n",
      "HelpfulnessDenominator    524587 non-null int64\n",
      "Score                     524587 non-null int64\n",
      "Time                      524587 non-null int64\n",
      "Summary                   524587 non-null object\n",
      "Text                      524587 non-null object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 44.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# CHecking for null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41159</th>\n",
       "      <td>44737</td>\n",
       "      <td>B001EQ55RW</td>\n",
       "      <td>A2V0I904FH7ABY</td>\n",
       "      <td>Ram</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1212883200</td>\n",
       "      <td>Pure cocoa taste with crunchy almonds inside</td>\n",
       "      <td>It was almost a 'love at first bite' - the per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59301</th>\n",
       "      <td>64422</td>\n",
       "      <td>B000MIDROQ</td>\n",
       "      <td>A161DK06JJMCYF</td>\n",
       "      <td>J. E. Stephens \"Jeanne\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1224892800</td>\n",
       "      <td>Bought This for My Son at College</td>\n",
       "      <td>My son loves spaghetti so I didn't hesitate or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id   ProductId          UserId              ProfileName  \\\n",
       "41159  44737  B001EQ55RW  A2V0I904FH7ABY                      Ram   \n",
       "59301  64422  B000MIDROQ  A161DK06JJMCYF  J. E. Stephens \"Jeanne\"   \n",
       "\n",
       "       HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "41159                     3                       2      1  1212883200   \n",
       "59301                     3                       1      1  1224892800   \n",
       "\n",
       "                                            Summary  \\\n",
       "41159  Pure cocoa taste with crunchy almonds inside   \n",
       "59301             Bought This for My Son at College   \n",
       "\n",
       "                                                    Text  \n",
       "41159  It was almost a 'love at first bite' - the per...  \n",
       "59301  My son loves spaghetti so I didn't hesitate or...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helpfulness numerator cant be greater then Helpfulness denominator\n",
    "\n",
    "df[df.HelpfulnessNumerator > df.HelpfulnessDenominator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524585, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ABove two rows to be deleted -\n",
    "\n",
    "df = df[df.HelpfulnessNumerator <= df.HelpfulnessDenominator]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    442867\n",
       "0     81718\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the dataframe balancing\n",
    "\n",
    "df.Score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "* Data Cleaning using Regex\n",
    "* Convert all to lower case\n",
    "* Stop word removal\n",
    "* Stemming\n",
    "* Lemmitization (regains the english meaning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm # for graphical  view of progress bar\n",
    "import re                      # for regular expression\n",
    "from bs4 import BeautifulSoup  # for removing the xml tags\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for regex clean\n",
    "\n",
    "def text_cleaning(sen):\n",
    "    sen = sen.lower()  # coverting all words to lower case\n",
    "    sen = BeautifulSoup(sen,'lxml').get_text()\n",
    "    sen = re.sub(r'<.*?>',\" \",sen)\n",
    "    sen = re.sub(\"\\S*\\d\\S*\", \"\", sen).strip()\n",
    "    sen = re.sub(r\"won't\", \"will not\", sen)\n",
    "    sen = re.sub(r\"can\\'t\", \"can not\", sen)\n",
    "    sen = re.sub(r\"n\\'t\", \" not\", sen)\n",
    "    sen = re.sub(r\"\\'re\", \" are\", sen)\n",
    "    sen = re.sub(r\"\\'s\", \" is\", sen)\n",
    "    sen = re.sub(r\"\\'d\", \" would\", sen)\n",
    "    sen = re.sub(r\"\\'ll\", \" will\", sen)\n",
    "    sen = re.sub(r\"\\'t\", \" not\", sen)\n",
    "    sen = re.sub(r\"\\'ve\", \" have\", sen)\n",
    "    sen = re.sub(r\"\\'m\", \" am\", sen)\n",
    "    sen = re.sub(r\"[^a-zA-Z0-9\\n]\",\" \",sen) # to remoce any special character\n",
    "    \n",
    "    return sen\n",
    "\n",
    "\n",
    "\n",
    "# importing stop words from NLTK---\n",
    "\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "check = ['no', 'nor', 'not']\n",
    "for i in check:\n",
    "    if i in stop_words:\n",
    "        stop_words.remove(i)\n",
    "\n",
    "\n",
    "        \n",
    "# importing Stemming--\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "\n",
    "# Importing Lemmatizer ---\n",
    "lemmetizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_text(review):\n",
    "    \n",
    "    processed_review = []\n",
    "    review = text_cleaning(review)\n",
    "    \n",
    "    for word in review.split():\n",
    "        if word not in stop_words:\n",
    "#             word = lemmetizer.lemmatize(word)\n",
    "            processed_review.append(word)\n",
    "            \n",
    "    return  (\" \".join(processed_review))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593.3213766 secs\n"
     ]
    }
   ],
   "source": [
    "a = time.clock()\n",
    "\n",
    "processed_review = df.Text.apply(processed_text)\n",
    "\n",
    "b = time.clock()\n",
    "print(b-a,\"secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524585,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_review.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=len(textp_w), stopwords=stopwords)\n",
    "wc.generate(textp_w)\n",
    "print (\"Word Cloud for Duplicate Question pairs\")\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    bought several vitality canned dog food produc...\n",
       "1    product arrived labeled jumbo salted peanuts p...\n",
       "2    confection around centuries light pillowy citr...\n",
       "3    looking secret ingredient robitussin believe f...\n",
       "4    great taffy great price wide assortment yummy ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampl = processed_review[0:5]\n",
    "sampl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WordListCorpusReader' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-9d36903d3009>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"white\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# generate word cloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mwc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"My name is haurya singh my name shaurya sahurya\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Word Cloud for non-Duplicate Question pairs:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bilinear'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m         \"\"\"\n\u001b[1;32m--> 619\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \"\"\"\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    555\u001b[0m         \"\"\"\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         flags = (re.UNICODE if sys.version < '3' and type(text) is unicode  # noqa: F821\n",
      "\u001b[1;31mTypeError\u001b[0m: 'WordListCorpusReader' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "wc = WordCloud(background_color=\"white\",stopwords=stopwords)\n",
    "# generate word cloud\n",
    "wc.generate(\"My name is haurya singh my name shaurya sahurya\")\n",
    "print (\"Word Cloud for non-Duplicate Question pairs:\")\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Featurization\n",
    "\n",
    "1. BOW\n",
    "2. Bi gram, N gram\n",
    "3. TF-IDF\n",
    "4. Word 2 vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524585, 119006)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vector = CountVectorizer()\n",
    "processed_review_bowvector = count_vector.fit_transform(processed_review)\n",
    "processed_review_bowvector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unoque words in corpus :  119006\n"
     ]
    }
   ],
   "source": [
    "count_vector.get_feature_names() # get_feature_names() gives all the unique words\n",
    "print(\"Number of unoque words in corpus : \",len(count_vector.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, ..., 0, 0, 0], dtype=int64)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(processed_review_bowvector[1].toarray() # vector corresponding the review 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaa',\n",
       " 'aaaaa',\n",
       " 'aaaaaa',\n",
       " 'aaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaargh',\n",
       " 'aaaaaaaaaaaaaaaaacccccccckkkkkk',\n",
       " 'aaaaaaaaagghh',\n",
       " 'aaaaaaah',\n",
       " 'aaaaaaahhhhhh',\n",
       " 'aaaaaaarrrrrggghhh',\n",
       " 'aaaaaah',\n",
       " 'aaaaaahhh',\n",
       " 'aaaaaahhhh',\n",
       " 'aaaaaahhhhh',\n",
       " 'aaaaaahhhhhyaaaaaa',\n",
       " 'aaaaaand',\n",
       " 'aaaaaawwwwwwwwww',\n",
       " 'aaaaah',\n",
       " 'aaaaahhhhhhhhhhhhhhhh',\n",
       " 'aaaaallll',\n",
       " 'aaaaawsome',\n",
       " 'aaaah',\n",
       " 'aaaahhhhhh']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.get_feature_names()[0:30]  # here all features were taken "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Bi-gram and N-grasm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524585, 10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram_range=(1,2) --> for the no of word in neighbour to take\n",
    "# min_df=10  ----> min number of occurence of word compu;sory to be get noticed\n",
    "# max_features =10000 ---> give top 10,000 fatures only out of all available\n",
    "\n",
    "\n",
    "count_vector_2 = CountVectorizer(ngram_range=(1,2), min_df=10, max_features=10000)\n",
    "processed_review_bigrams = count_vector_2.fit_transform(processed_review)\n",
    "processed_review_bigrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'able buy',\n",
       " 'able eat',\n",
       " 'able find',\n",
       " 'able get',\n",
       " 'able make',\n",
       " 'able order',\n",
       " 'able purchase',\n",
       " 'able use',\n",
       " 'absolute',\n",
       " 'absolute best',\n",
       " 'absolute favorite',\n",
       " 'absolutely',\n",
       " 'absolutely best',\n",
       " 'absolutely delicious',\n",
       " 'absolutely love',\n",
       " 'absolutely loved',\n",
       " 'absolutely loves',\n",
       " 'absolutely no',\n",
       " 'absolutely wonderful',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'acai',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector_2.get_feature_names()[:30]    # only top 10,000  features were taekn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_review_bigrams[1].toarray() # vector corresponding the review 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524585, 10000)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vector = TfidfVectorizer(ngram_range=(1,2), min_df=10, max_features=10000)\n",
    "processed_review_tfidf = tf_idf_vector.fit_transform(processed_review)\n",
    "processed_review_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'able buy',\n",
       " 'able eat',\n",
       " 'able find',\n",
       " 'able get',\n",
       " 'able make',\n",
       " 'able order',\n",
       " 'able purchase',\n",
       " 'able use',\n",
       " 'absolute',\n",
       " 'absolute best',\n",
       " 'absolute favorite',\n",
       " 'absolutely',\n",
       " 'absolutely best',\n",
       " 'absolutely delicious',\n",
       " 'absolutely love',\n",
       " 'absolutely loved',\n",
       " 'absolutely loves',\n",
       " 'absolutely no',\n",
       " 'absolutely wonderful',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'acai',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vector.get_feature_names()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_review_tfidf[1].toarray() # vector corresponding the review 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Word 2 Vec\n",
    "\n",
    "It can be implemented by 2 ways\n",
    "* By using google trained google news corpus\n",
    "* By trainning own corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Word2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-2c6f5acac943>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# min_count = 5 considers only words that occured atleast 5 times\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mw2v_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_review\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Word2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "# min_count = 5 considers only words that occured atleast 5 times\n",
    "\n",
    "# w2v_model = Word2Vec(processed_review, min_count=5, size=50, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unable to install it on windows 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Bi-Ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import auc, confusion_matrix,log_loss, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x ,x_bigram_test , y , y_bigram_test = train_test_split(processed_review_bigrams , df.Score, stratify =df.Score, random_state=0, test_size=0.20 )\n",
    "x_bigram_train, x_bigram_cv, y_train, y_cv = train_test_split(x,y,stratify=y,random_state=0,test_size=0.20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha :  1e-05  Log loss =  0.1713843204634063\n",
      "For alpha :  0.0001  Log loss =  0.15803087518531844\n",
      "For alpha :  0.001  Log loss =  0.1874473702293829\n",
      "For alpha :  0.01  Log loss =  0.2559888701195097\n",
      "For alpha :  0.1  Log loss =  0.389877011007419\n",
      "For alpha :  1  Log loss =  0.4325988679687597\n",
      "For alpha :  10  Log loss =  0.43116893069107465\n"
     ]
    }
   ],
   "source": [
    "alpha = [10**x for x in range(-5,2)]\n",
    "auc_cv = []\n",
    "log_loss_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(loss='log', penalty='l2',alpha=i,random_state=0)\n",
    "    clf.fit(x_bigram_train, y_train)\n",
    "    sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "    sigmoid_clf.fit(x_bigram_train, y_train)\n",
    "    predicted_y = sigmoid_clf.predict_proba(x_bigram_cv)\n",
    "    loss = log_loss(y_cv, predicted_y,labels=clf.classes_)\n",
    "    log_loss_array.append(loss)\n",
    "    print(\"For alpha : \",i,\" Log loss = \",loss)\n",
    "#     auc_cv.append(roc_auc_score(y_cv,predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At alpha = 0.0001, For Test Data Log loss is :  0.156188911103147\n"
     ]
    }
   ],
   "source": [
    "# log loss is min At alpha = 0.0001\n",
    "# trainng model at best alpha\n",
    "\n",
    "clf = SGDClassifier(loss='log', penalty='l2',alpha=0.0001,random_state=0)\n",
    "clf.fit(x_bigram_train, y_train)\n",
    "sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "sigmoid_clf.fit(x_bigram_train, y_train)\n",
    "predicted_y = sigmoid_clf.predict_proba(x_bigram_test)\n",
    "loss = log_loss(y_bigram_test, predicted_y,labels=clf.classes_)\n",
    "print(\" At alpha = 0.0001, For Test Data Log loss is : \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable    \n",
    "tbl = PrettyTable()\n",
    "tbl.field_names = [\"ML Model\",\"Vectorizer\",\"Regularization\", \"Hyperameter(alpha)\", \"Cv Log Loss\",'Test log loss']\n",
    "tbl.add_row(['Logistic Class.','Bi Gram','l2','0.0001','1.158','0.156'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "|     ML Model    | Vectorizer | Regularization | Hyperameter(alpha) | Cv Log Loss | Test log loss |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "| Logistic Class. |  Bi Gram   |       l2       |       0.0001       |    1.158    |     0.156     |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "print(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (TF-IDF, with L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "x ,x_tfidf_test , y , y_tfidf_test = train_test_split(processed_review_tfidf , df.Score, stratify =df.Score, random_state=0, test_size=0.20 )\n",
    "x_tfidf_train, x_tfidf_cv, y_train, y_cv = train_test_split(x,y,stratify=y,random_state=0,test_size=0.20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha :  1e-05  Log loss =  0.15062224672769398\n",
      "For alpha :  0.0001  Log loss =  0.18834416566953543\n",
      "For alpha :  0.001  Log loss =  0.23546356816048053\n",
      "For alpha :  0.01  Log loss =  0.27559481342936687\n",
      "For alpha :  0.1  Log loss =  0.4160471346161671\n",
      "For alpha :  1  Log loss =  0.4238655594400876\n",
      "For alpha :  10  Log loss =  0.42454152072136825\n"
     ]
    }
   ],
   "source": [
    "alpha = [10**x for x in range(-5,2)]\n",
    "log_loss_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(loss='log', penalty='l2',alpha=i,random_state=0)\n",
    "    clf.fit(x_tfidf_train, y_train)\n",
    "    sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "    sigmoid_clf.fit(x_tfidf_train, y_train)\n",
    "    predicted_y = sigmoid_clf.predict_proba(x_tfidf_cv)\n",
    "    loss = log_loss(y_cv, predicted_y,labels=clf.classes_)\n",
    "    log_loss_array.append(loss)\n",
    "    print(\"For alpha : \",i,\" Log loss = \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At alpha = 0.00001, For Test Data Log loss is :  0.14865336110185484\n"
     ]
    }
   ],
   "source": [
    "# log loss is min At alpha = 0.00001\n",
    "# trainng model at best alpha\n",
    "\n",
    "clf = SGDClassifier(loss='log', penalty='l2',alpha=0.00001,random_state=0)\n",
    "clf.fit(x_tfidf_train, y_train)\n",
    "sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "sigmoid_clf.fit(x_tfidf_train, y_train)\n",
    "predicted_y = sigmoid_clf.predict_proba(x_tfidf_test)\n",
    "loss = log_loss(y_tfidf_test, predicted_y,labels=clf.classes_)\n",
    "print(\" At alpha = 0.00001, For Test Data Log loss is : \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "|     ML Model    | Vectorizer | Regularization | Hyperameter(alpha) | Cv Log Loss | Test log loss |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "| Logistic Class. |   TF-IDF   |       l2       |       0.0001       |    0.150    |     0.148     |\n",
      "| Logistic Class. |  Bi Gram   |       l2       |       0.0001       |    0.158    |     0.156     |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "print(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x ,x_bow_test , y , y_bow_test = train_test_split(processed_review_bowvector , df.Score, stratify =df.Score, random_state=0, test_size=0.20 )\n",
    "x_bow_train, x_bow_cv, y_train, y_cv = train_test_split(x,y,stratify=y,random_state=0,test_size=0.20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha :  1e-05  Log loss =  0.18976661954055318\n",
      "For alpha :  0.0001  Log loss =  0.18036185983962616\n",
      "For alpha :  0.001  Log loss =  0.2056061930639523\n",
      "For alpha :  0.01  Log loss =  0.2665360184991525\n",
      "For alpha :  0.1  Log loss =  0.39383617053238773\n",
      "For alpha :  1  Log loss =  0.4325819688580151\n",
      "For alpha :  10  Log loss =  0.43109077725845746\n"
     ]
    }
   ],
   "source": [
    "alpha = [10**x for x in range(-5,2)]\n",
    "log_loss_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(loss='log', penalty='l2',alpha=i,random_state=0)\n",
    "    clf.fit(x_bow_train, y_train)\n",
    "    sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "    sigmoid_clf.fit(x_bow_train, y_train)\n",
    "    predicted_y = sigmoid_clf.predict_proba(x_bow_cv)\n",
    "    loss = log_loss(y_cv, predicted_y,labels=clf.classes_)\n",
    "    log_loss_array.append(loss)\n",
    "    print(\"For alpha : \",i,\" Log loss = \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At alpha = 0.00001, For Test Data Log loss is :  0.17968136206410937\n"
     ]
    }
   ],
   "source": [
    "# log loss is min At alpha = 0.0001\n",
    "# trainng model at best alpha\n",
    "\n",
    "clf = SGDClassifier(loss='log', penalty='l2',alpha=0.0001,random_state=0)\n",
    "clf.fit(x_bow_train, y_train)\n",
    "sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "sigmoid_clf.fit(x_bow_train, y_train)\n",
    "predicted_y = sigmoid_clf.predict_proba(x_bow_test)\n",
    "loss = log_loss(y_bow_test, predicted_y,labels=clf.classes_)\n",
    "print(\" At alpha = 0.00001, For Test Data Log loss is : \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97104"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = clf.coef_\n",
    "np.count_nonzero(weight)  # 'L1' regularizatio produces saprse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.add_row(['Logistic Class.','BOW','l2','0.0001','0.180','0.179'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "|     ML Model    | Vectorizer | Regularization | Hyperameter(alpha) | Cv Log Loss | Test log loss |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "| Logistic Class. |   TF-IDF   |       l2       |       0.0001       |    0.150    |     0.148     |\n",
      "| Logistic Class. |  Bi Gram   |       l2       |       0.0001       |    0.158    |     0.156     |\n",
      "| Logistic Class. |    BOW     |       l2       |       0.0001       |    0.180    |     0.179     |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "print(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (TF-IDF, with L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha :  1e-05  Log loss =  0.15568907055150208\n",
      "For alpha :  0.0001  Log loss =  0.22288634676872407\n",
      "For alpha :  0.001  Log loss =  0.3784774308292144\n",
      "For alpha :  0.01  Log loss =  0.432600624819805\n",
      "For alpha :  0.1  Log loss =  0.4326006248198049\n",
      "For alpha :  1  Log loss =  0.43260062481980505\n",
      "For alpha :  10  Log loss =  0.4326006248198049\n"
     ]
    }
   ],
   "source": [
    "alpha = [10**x for x in range(-5,2)]\n",
    "log_loss_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(loss='log', penalty='l1',alpha=i,random_state=0)\n",
    "    clf.fit(x_tfidf_train, y_train)\n",
    "    sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "    sigmoid_clf.fit(x_tfidf_train, y_train)\n",
    "    predicted_y = sigmoid_clf.predict_proba(x_tfidf_cv)\n",
    "    loss = log_loss(y_cv, predicted_y,labels=clf.classes_)\n",
    "    log_loss_array.append(loss)\n",
    "    print(\"For alpha : \",i,\" Log loss = \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At alpha = 0.00001, For Test Data Log loss is :  0.14865336110185484\n"
     ]
    }
   ],
   "source": [
    "# log loss is min At alpha = 0.00001\n",
    "# trainng model at best alpha\n",
    "\n",
    "clf = SGDClassifier(loss='log', penalty='l2',alpha=0.00001,random_state=0)\n",
    "clf.fit(x_tfidf_train, y_train)\n",
    "sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "sigmoid_clf.fit(x_tfidf_train, y_train)\n",
    "predicted_y = sigmoid_clf.predict_proba(x_tfidf_test)\n",
    "loss = log_loss(y_tfidf_test, predicted_y,labels=clf.classes_)\n",
    "print(\" At alpha = 0.00001, For Test Data Log loss is : \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "|     ML Model    | Vectorizer | Regularization | Hyperameter(alpha) | Cv Log Loss | Test log loss |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "| Logistic Class. |   TF-IDF   |       l2       |       0.0001       |    0.150    |     0.148     |\n",
      "| Logistic Class. |  Bi Gram   |       l2       |       0.0001       |    0.158    |     0.156     |\n",
      "| Logistic Class. |    BOW     |       l2       |       0.0001       |    0.180    |     0.179     |\n",
      "| Logistic Class. |   TF-IDF   |       l1       |      0.00001       |    0.156    |     0.148     |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "tbl.add_row(['Logistic Class.','TF-IDF','l1','0.00001','0.156','0.148'])\n",
    "print(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Bi-Ngram, L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha :  1e-05  Log loss =  0.16958512944837217\n",
      "For alpha :  0.0001  Log loss =  0.19452603275162178\n",
      "For alpha :  0.001  Log loss =  0.25556242818702735\n",
      "For alpha :  0.01  Log loss =  0.3884248816500186\n",
      "For alpha :  0.1  Log loss =  0.4212649871906855\n",
      "For alpha :  1  Log loss =  0.43260062481980505\n",
      "For alpha :  10  Log loss =  0.4326006248198049\n"
     ]
    }
   ],
   "source": [
    "alpha = [10**x for x in range(-5,2)]\n",
    "auc_cv = []\n",
    "log_loss_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(loss='log', penalty='l1',alpha=i,random_state=0)\n",
    "    clf.fit(x_bigram_train, y_train)\n",
    "    sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "    sigmoid_clf.fit(x_bigram_train, y_train)\n",
    "    predicted_y = sigmoid_clf.predict_proba(x_bigram_cv)\n",
    "    loss = log_loss(y_cv, predicted_y,labels=clf.classes_)\n",
    "    log_loss_array.append(loss)\n",
    "    print(\"For alpha : \",i,\" Log loss = \",loss)\n",
    "#     auc_cv.append(roc_auc_score(y_cv,predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At alpha = 0.0001, For Test Data Log loss is :  2.2231345583115054\n"
     ]
    }
   ],
   "source": [
    "# log loss is min At alpha = 0.00001\n",
    "# trainng model at best alpha\n",
    "\n",
    "clf = SGDClassifier(loss='log', penalty='l1',alpha=0.00001,random_state=0)\n",
    "clf.fit(x_bigram_train, y_train)\n",
    "sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "sigmoid_clf.fit(x_bigram_train, y_train)\n",
    "predicted_y = sigmoid_clf.predict(x_bigram_test)\n",
    "loss = log_loss(y_bigram_test, predicted_y,labels=clf.classes_)\n",
    "print(\" At alpha = 0.0001, For Test Data Log loss is : \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7461"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = clf.coef_\n",
    "np.count_nonzero(weight) # 'L1' regularizatio produces dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "|     ML Model    | Vectorizer | Regularization | Hyperameter(alpha) | Cv Log Loss | Test log loss |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "| Logistic Class. |   TF-IDF   |       l2       |       0.0001       |    0.150    |     0.148     |\n",
      "| Logistic Class. |  Bi Gram   |       l2       |       0.0001       |    0.158    |     0.156     |\n",
      "| Logistic Class. |    BOW     |       l2       |       0.0001       |    0.180    |     0.179     |\n",
      "| Logistic Class. |   TF-IDF   |       l1       |      0.00001       |    0.156    |     0.148     |\n",
      "| Logistic Class. |  Bi-Gram   |       l1       |      0.00001       |    0.170    |     0.169     |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "tbl.add_row(['Logistic Class.','Bi-Gram','l1','0.00001','0.170','0.169'])\n",
    "print(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "con = confusion_matrix(y_bigram_test, predicted_y)\n",
    "\n",
    "class_label = [\"negative\", \"positive\"]\n",
    "df_plot = pd.DataFrame(con, index = class_label, columns = class_label)\n",
    "sns.heatmap(df_plot, annot = True,fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>11027</td>\n",
       "      <td>5317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1436</td>\n",
       "      <td>87137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          negative  positive\n",
       "negative     11027      5317\n",
       "positive      1436     87137"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11027,  5317],\n",
       "       [ 1436, 87137]], dtype=int64)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the lenth of string at the end of each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_review = processed_review.map(lambda x: x + \" \"+str(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "|     ML Model    | Vectorizer | Regularization | Hyperameter(alpha) | Cv Log Loss | Test log loss |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "| Logistic Class. |   TF-IDF   |       l2       |       0.0001       |    0.150    |     0.148     |\n",
      "| Logistic Class. |  Bi Gram   |       l2       |       0.0001       |    0.158    |     0.156     |\n",
      "| Logistic Class. |    BOW     |       l2       |       0.0001       |    0.180    |     0.179     |\n",
      "| Logistic Class. |   TF-IDF   |       l1       |      0.00001       |    0.156    |     0.148     |\n",
      "| Logistic Class. |  Bi-Gram   |       l1       |      0.00001       |    0.170    |     0.169     |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "print(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainng model with feature engg on Top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha :  1e-05  Log loss =  0.15062224672769398\n",
      "For alpha :  0.0001  Log loss =  0.18834416566953543\n",
      "For alpha :  0.001  Log loss =  0.23546356816048053\n",
      "For alpha :  0.01  Log loss =  0.27559481342936687\n",
      "For alpha :  0.1  Log loss =  0.4160471346161671\n",
      "For alpha :  1  Log loss =  0.4238655594400876\n",
      "For alpha :  10  Log loss =  0.42454152072136825\n"
     ]
    }
   ],
   "source": [
    "alpha = [10**x for x in range(-5,2)]\n",
    "log_loss_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(loss='log', penalty='l2',alpha=i,random_state=0)\n",
    "    clf.fit(x_tfidf_train, y_train)\n",
    "    sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "    sigmoid_clf.fit(x_tfidf_train, y_train)\n",
    "    predicted_y = sigmoid_clf.predict_proba(x_tfidf_cv)\n",
    "    loss = log_loss(y_cv, predicted_y,labels=clf.classes_)\n",
    "    log_loss_array.append(loss)\n",
    "    print(\"For alpha : \",i,\" Log loss = \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At alpha = 0.00001, For Test Data Log loss is :  0.14865336110185484\n"
     ]
    }
   ],
   "source": [
    "# log loss is min At alpha = 0.00001\n",
    "# trainng model at best alpha\n",
    "\n",
    "clf = SGDClassifier(loss='log', penalty='l2',alpha=0.00001,random_state=0)\n",
    "clf.fit(x_tfidf_train, y_train)\n",
    "sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "sigmoid_clf.fit(x_tfidf_train, y_train)\n",
    "predicted_y = sigmoid_clf.predict_proba(x_tfidf_test)\n",
    "loss = log_loss(y_tfidf_test, predicted_y,labels=clf.classes_)\n",
    "print(\" At alpha = 0.00001, For Test Data Log loss is : \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(loss='log', penalty='l2',alpha=0.00001,random_state=0)\n",
    "clf.fit(x_tfidf_train, y_train)\n",
    "predicted_y = clf.predict(x_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11207,  5137],\n",
       "       [ 1399, 87174]], dtype=int64)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = confusion_matrix(y_tfidf_test, predicted_y)\n",
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_plot = pd.DataFrame(data =con ,index = class_label ,columns = class_label)\n",
    "class_label = [\"Negative\",\"Positive\"]\n",
    "sns.heatmap(df_plot,annot = True,fmt=\"d\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting top 10 features from Model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  tf_idf_vector --- this contains all the features\n",
    "tf_all_features = tf_idf_vector.get_feature_names()\n",
    "len(tf_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weighted hy[erplane vector 'weight vector'\n",
    "weight_vector = clf.coef_\n",
    "weight_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_a = np.argsort(weight_vector)[:,::-1]\n",
    "pos_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10000)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_a = np.argsort(weight_vector)\n",
    "neg_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great\n",
      "delicious\n",
      "best\n",
      "perfect\n",
      "good\n",
      "loves\n",
      "not disappointed\n",
      "love\n",
      "excellent\n",
      "wonderful\n"
     ]
    }
   ],
   "source": [
    "# top +ive words --\n",
    "for i in range(0,10):\n",
    "    print(tf_all_features[pos_a[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappointed\n",
      "worst\n",
      "disappointing\n",
      "not worth\n",
      "not good\n",
      "not recommend\n",
      "terrible\n",
      "awful\n",
      "not\n",
      "not buy\n"
     ]
    }
   ],
   "source": [
    "# top negative words ---\n",
    "for i in range(0,10):\n",
    "    print(tf_all_features[neg_a[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "|     ML Model    | Vectorizer | Regularization | Hyperameter(alpha) | Cv Log Loss | Test log loss |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "| Logistic Class. |   TF-IDF   |       l2       |       0.0001       |    0.150    |     0.148     |\n",
      "| Logistic Class. |  Bi Gram   |       l2       |       0.0001       |    0.158    |     0.156     |\n",
      "| Logistic Class. |    BOW     |       l2       |       0.0001       |    0.180    |     0.179     |\n",
      "| Logistic Class. |   TF-IDF   |       l1       |      0.00001       |    0.156    |     0.148     |\n",
      "| Logistic Class. |  Bi-Gram   |       l1       |      0.00001       |    0.170    |     0.169     |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "print(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM (Bi-gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha :  1e-05  Log loss =  0.17147212128724118\n",
      "For alpha :  0.0001  Log loss =  0.1572332708355313\n",
      "For alpha :  0.001  Log loss =  0.16991852334223542\n",
      "For alpha :  0.01  Log loss =  0.20454672270750435\n",
      "For alpha :  0.1  Log loss =  0.36261523663011647\n",
      "For alpha :  1  Log loss =  0.43247861984180797\n",
      "For alpha :  10  Log loss =  0.43094396826788645\n"
     ]
    }
   ],
   "source": [
    "alpha = [10**x for x in range(-5,2)]\n",
    "log_loss_array = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = SGDClassifier(loss='hinge', penalty='l2',alpha=i,random_state=0)\n",
    "    clf.fit(x_bigram_train, y_train)\n",
    "    sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "    sigmoid_clf.fit(x_bigram_train, y_train)\n",
    "    predicted_y = sigmoid_clf.predict_proba(x_bigram_cv)\n",
    "    loss = log_loss(y_cv, predicted_y,labels=clf.classes_)\n",
    "    log_loss_array.append(loss)\n",
    "    print(\"For alpha : \",i,\" Log loss = \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " At alpha = 0.0001, For Test Data Log loss is :  1.9765559262138674\n"
     ]
    }
   ],
   "source": [
    "# log loss is min At alpha = 0.0001\n",
    "# trainng model at best alpha\n",
    "\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2',alpha=0.0001,random_state=0)\n",
    "clf.fit(x_bigram_train, y_train)\n",
    "sigmoid_clf = CalibratedClassifierCV(clf, method='sigmoid')\n",
    "sigmoid_clf.fit(x_bigram_train, y_train)\n",
    "predicted_y = sigmoid_clf.predict(x_bigram_test)\n",
    "loss = log_loss(y_bigram_test, predicted_y,labels=clf.classes_)\n",
    "print(\" At alpha = 0.0001, For Test Data Log loss is : \",loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "|     ML Model    | Vectorizer | Regularization | Hyperameter(alpha) | Cv Log Loss | Test log loss |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "| Logistic Class. |   TF-IDF   |       l2       |       0.0001       |    0.150    |     0.148     |\n",
      "| Logistic Class. |  Bi Gram   |       l2       |       0.0001       |    0.158    |     0.156     |\n",
      "| Logistic Class. |    BOW     |       l2       |       0.0001       |    0.180    |     0.179     |\n",
      "| Logistic Class. |   TF-IDF   |       l1       |      0.00001       |    0.156    |     0.148     |\n",
      "| Logistic Class. |  Bi-Gram   |       l1       |      0.00001       |    0.170    |     0.169     |\n",
      "|   Linear SVM.   |  Bi-Gram   |       l2       |       0.0001       |    0.157    |      1.97     |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "tbl.add_row(['Linear SVM.','Bi-Gram','l2','0.0001','0.157','1.97'])\n",
    "print(tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For linear SVM despite of Hyperparameter trainning We see marginal difference with the cv_log loss and Test log loss\n",
    "* Thus model has High Variance\n",
    "* Model is useless as hypertunning is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "|     ML Model    | Vectorizer | Regularization | Hyperameter(alpha) | Cv Log Loss | Test log loss |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n",
      "| Logistic Class. |   TF-IDF   |       l2       |       0.0001       |    0.150    |     0.148     |\n",
      "+-----------------+------------+----------------+--------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "print(tbl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression best with the above Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
